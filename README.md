# ğŸ—ï¸ Pipeline ETL con Python y MySQL

## ğŸ§  DescripciÃ³n
Este proyecto implementa un **pipeline ETL (Extract, Transform, Load)** utilizando **Python y MySQL**, simulando un flujo de datos real bajo buenas prÃ¡cticas de **Data Engineering**.

El objetivo es extraer datos (reales o sintÃ©ticos), transformarlos y cargarlos en una base de datos MySQL, manteniendo separaciÃ³n de responsabilidades, control de configuraciÃ³n, logging y versionado.

El proyecto estÃ¡ orientado a demostrar un **nivel intermedio** de conocimientos en pipelines de datos.

---

## ğŸ—ï¸ Arquitectura del Pipeline
El flujo del pipeline sigue una estructura clara y desacoplada:

GeneraciÃ³n / Fuente de Datos
â†“
ExtracciÃ³n (CSV / Datos sintÃ©ticos)
â†“
TransformaciÃ³n con Python
â†“
Carga a MySQL
â†“
Persistencia y Logging

yaml
Copiar cÃ³digo

---

## ğŸš€ Funcionalidades principales
- GeneraciÃ³n de datos sintÃ©ticos para pruebas
- ExtracciÃ³n de datos desde archivos CSV
- Transformaciones con Python
- CreaciÃ³n de tablas en MySQL mediante scripts SQL
- Carga automatizada de datos a MySQL
- Registro de eventos y errores mediante logging
- ConfiguraciÃ³n desacoplada mediante archivo de configuraciÃ³n
- Manejo de variables de entorno

---

## ğŸ› ï¸ TecnologÃ­as utilizadas
- **Python** â€“ desarrollo del pipeline ETL
- **MySQL** â€“ base de datos relacional
- **SQL** â€“ creaciÃ³n y gestiÃ³n de tablas
- **Visual Studio Code** â€“ entorno de desarrollo
- **Git & GitHub** â€“ control de versiones
- **Virtual Environment (venv)** â€“ aislamiento de dependencias

---

## ğŸ“‚ Estructura del proyecto

etl_mysql_project/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ ventas_raw.csv # Datos de entrada (raw)
â”‚ â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ logs/
â”‚ â”œâ”€â”€ etl.log # Logs del pipeline
â”‚ â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ sql/
â”‚ â””â”€â”€ create_tables.sql # Script SQL para crear tablas
â”‚
â”œâ”€â”€ venv/ # Entorno virtual (no versionado)
â”‚
â”œâ”€â”€ config.py # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ etl_pipeline.py # Script principal del pipeline ETL
â”œâ”€â”€ generate_synthetic_data.py# GeneraciÃ³n de datos de prueba
â”œâ”€â”€ requirements.txt # Dependencias del proyecto
â”œâ”€â”€ .env.example # Variables de entorno de ejemplo
â””â”€â”€ README.md

yaml
Copiar cÃ³digo

---

## âš™ï¸ ConfiguraciÃ³n del entorno

### 1ï¸âƒ£ Crear entorno virtual
```bash
python -m venv venv
2ï¸âƒ£ Activar entorno virtual
Windows

bash
Copiar cÃ³digo
venv\Scripts\activate
Linux / Mac

bash
Copiar cÃ³digo
source venv/bin/activate
3ï¸âƒ£ Instalar dependencias
bash
Copiar cÃ³digo
pip install -r requirements.txt
4ï¸âƒ£ Configurar variables de entorno
Crear un archivo .env basado en .env.example y completar los valores:

env
Copiar cÃ³digo
DB_HOST=localhost
DB_PORT=3306
DB_NAME=nombre_base_datos
DB_USER=usuario
DB_PASSWORD=password
ğŸ—„ï¸ Base de datos MySQL
Antes de ejecutar el pipeline:

Crear la base de datos en MySQL

Ejecutar el script de creaciÃ³n de tablas:

sql
Copiar cÃ³digo
sql/create_tables.sql
â–¶ï¸ EjecuciÃ³n del pipeline
Generar datos sintÃ©ticos (opcional)
bash
Copiar cÃ³digo
python generate_synthetic_data.py
Ejecutar el pipeline ETL
bash
Copiar cÃ³digo
python etl_pipeline.py
Durante la ejecuciÃ³n:

Los datos son procesados y cargados en MySQL

Los eventos y errores quedan registrados en logs/etl.log

ğŸ“Š Logging y monitoreo
El pipeline implementa logging para:

Inicio y fin del proceso ETL

Errores de conexiÃ³n

Fallos en transformaciÃ³n o carga

Validaciones bÃ¡sicas

Esto permite trazabilidad y facilita el debugging del proceso.

ğŸ“ˆ Aprendizajes y buenas prÃ¡cticas
DiseÃ±o de pipelines ETL desacoplados

Uso de scripts SQL para control de esquema

Manejo de variables de entorno

ImplementaciÃ³n de logging en procesos de datos

SeparaciÃ³n entre datos, lÃ³gica y configuraciÃ³n

SimulaciÃ³n de flujos reales de Data Engineering

ğŸ¯ Enfoque profesional
Este proyecto estÃ¡ orientado a roles como:

Data Engineer

Analista de Datos TÃ©cnico

Desarrollador Python enfocado en datos

Presenta un enfoque prÃ¡ctico y realista, mÃ¡s allÃ¡ de ejercicios acadÃ©micos.
